<?xml version="1.0" encoding="UTF-8" ?>

<chapter xml:id="ch-ttests">
  <title>t-tests</title>
  
  <introduction>
    <p>
      Back in the day, William Sealy Gosset got a job working for Guinness Breweries. They make the famous Irish stout called Guinness. What happens next went something like this (total fabrication, but mostly on point).
    </p>

    <p>
      Guinness wanted all of their beers to be the best beers. No mistakes, no bad beers. They wanted to improve their quality control so that when Guinness was poured anywhere in the world, it would always comes out fantastic: 5 stars out of 5 every time, the best.
    </p>

    <p>
      Guinness had some beer tasters, who were super-experts. Every time they tasted a Guinness from the factory that wasn't 5 out of 5, they knew right away.
    </p>

    <p>
      But, Guinness had a big problem. They would make a keg of beer, and they would want to know if every single pint that would come out would be a 5 out of 5. So, the beer tasters drank pint after pint out of the keg, until it was gone. Some kegs were all 5 out of 5s. Some weren't, Guinness needed to fix that. But, the biggest problem was that, after the testing, there <alert>was no beer left to sell</alert>, the testers drank it all (remember I'm making this part up to illustrate a point, they probably still had beer left to sell).
    </p>

    <p>
      Guinness had a sampling and population problem. They wanted to know that the entire population of the beers they made were all 5 out of 5 stars. But, if they sampled the entire population, they would drink all of their beer, and wouldn't have any left to sell.
    </p>

    <p>
      Enter William Sealy Gosset. Gosset figured out the solution to the problem. He asked questions like this:
    </p>

    <p>
      <ol>
        <li>How many samples do I need to take to know the whole population is 5 out of 5?</li>
        <li>What's the fewest amount of samples I need to take to know the above, that would mean Guinness could test fewer beers for quality, sell more beers for profit, and make the product testing time shorter.</li>
      </ol>
    </p>

    <p>
      Gosset solved those questions, and he invented something called the <em>Student's t-test</em>. Gosset was working for Guinness, and could be fired for releasing trade-secrets that he invented (the t-test). But, Gosset published the work anyways, under a pseudonym. He called himself Student, hence Student's t-test. Now you know the rest of the story.
    </p>

    <p>
      It turns out this was a very nice thing for Gosset to have done. t-tests are used all the time, and they are useful, that's why they are used. In this chapter we learn how they work.
    </p>

    <p>
      You'll be surprised to learn that what we've already talked about, (the Crump Test, and the Randomization Test), are both very very similar to the t-test. So, in general, you have already been thinking about the things you need to think about to understand t-tests. You're probably wondering what is this <m>t</m>, what does <m>t</m> mean? We will tell you. Before we tell what it means, we first tell you about one more idea.
    </p>
  </introduction>

  <section xml:id="sec-confidence-mean">
    <title>Check your confidence in your mean</title>
    
    <p>
      We've talked about getting a sample of data. We know we can find the mean, we know we can find the standard deviation. We know we can look at the data in a histogram. These are all useful things to do for us to learn something about the properties of our data.
    </p>

    <p>
      You might be thinking of the mean and standard deviation as very different things that we would not put together. The mean is about central tendency (where most of the data is), and the standard deviation is about variance (where most of the data isn't). Yes, they are different things, but we can use them together to create useful new things.
    </p>

    <p>
      What if I told you my sample mean was 50, and I told you nothing else about my sample. Would you be confident that most of the numbers were near 50? Would you wonder if there was a lot of variability in the sample, and many of the numbers were very different from 50. You should wonder all of those things. The mean alone, just by itself, doesn't tell you anything about well the mean represents all of the numbers in the sample.
    </p>

    <p>
      It could be a representative number, when the standard deviation is very small, and all the numbers are close to 50. It could be a non-representative number, when the standard deviation is large, and many of the numbers are not near 50. You need to know the standard deviation in order to be confident in how well the mean represents the data.
    </p>

    <p>
      How can we put the mean and the standard deviation together, to give us a new number that tells us about confidence in the mean?
    </p>

    <p>
      We can do this using a ratio:
    </p>

    <p>
      <me>\frac{\text{mean}}{\text{standard deviation}}</me>
    </p>

    <p>
      Think about what happens here. We are dividing a number by a number. Look at what happens:
    </p>

    <p>
      <me>\frac{\text{number}}{\text{same number}} = 1</me>
    </p>

    <p>
      <me>\frac{\text{number}}{\text{smaller number}} = \text{big number}</me>
    </p>

    <p>
      compared to:
    </p>

    <p>
      <me>\frac{\text{number}}{\text{bigger number}} = \text{smaller number}</me>
    </p>

    <p>
      Imagine we have a mean of 50, and a truly small standard deviation of 1. What do we get with our formula?
    </p>

    <p>
      <me>\frac{50}{1} = 50</me>
    </p>

    <p>
      Imagine we have a mean of 50, and a big standard deviation of 100. What do we get with our formula?
    </p>

    <p>
      <me>\frac{50}{100} = 0.5</me>
    </p>

    <p>
      Notice, when we have a mean paired with a small standard deviation, our formula gives us a big number, like 50. When we have a mean paired with a large standard deviation, our formula gives us a small number, like 0.5. These numbers can tell us something about confidence in our mean, in a general way. We can be 50 confident in our mean in the first case, and only 0.5 (not at a lot) confident in the second case.
    </p>

    <p>
      What did we do here? We created a descriptive statistic by dividing the mean by the standard deviation. And, we have a sense of how to interpret this number, when it's big we're more confident that the mean represents all of the numbers, when it's small we are less confident. This is a useful kind of number, a ratio between what we think about our sample (the mean), and the variability in our sample (the standard deviation). Get used to this idea. Almost everything that follows in this textbook is based on this kind of ratio. We will see that our ratio turns into different kinds of <q>statistics</q>, and the ratios will look like this in general:
    </p>

    <p>
      <me>\text{name of statistic} = \frac{\text{measure of what we know}}{\text{measure of what we don't know}}</me>
    </p>

    <p>
      or, to say it using different words:
    </p>

    <p>
      <me>\text{name of statistic} = \frac{\text{measure of effect}}{\text{measure of error}}</me>
    </p>

    <p>
      In fact, this is the general formula for the t-test. Big surprise!
    </p>
  </section>

  <section xml:id="sec-one-sample-ttest">
    <title>One-sample t-test: A new t-test</title>
    
    <p>
      Now we are ready to talk about t-test. We will talk about three of them. We start with the one-sample t-test.
    </p>

    <p>
      Commonly, the one-sample t-test is used to estimate the chances that your sample came from a particular population. Specifically, you might want to know whether the mean that you found from your sample, could have come from a particular population having a particular mean.
    </p>

    <p>
      Straight away, the one-sample t-test becomes a little confusing (and I haven't even described it yet). Officially, it uses known parameters from the population, like the mean of the population and the standard deviation of the population. However, most times you don't know those parameters of the population! So, you have to estimate them from your sample. Remember from the chapters on descriptive statistics and sampling, our sample mean is an unbiased estimate of the population mean. And, our sample standard deviation (the one where we divide by n-1) is an unbiased estimate of the population standard deviation. When Gosset developed the t-test, he recognized that he could use these estimates from his samples, to make the t-test. Here is the formula for the one sample t-test, we first use words, and then become more specific:
    </p>

    <subsection xml:id="subsec-formulas-one-sample">
      <title>Formulas for one-sample t-test</title>
      
      <p>
        <me>\text{name of statistic} = \frac{\text{measure of effect}}{\text{measure of error}}</me>
      </p>

      <p>
        <me>t = \frac{\text{measure of effect}}{\text{measure of error}}</me>
      </p>

      <p>
        <me>t = \frac{\text{Mean difference}}{\text{standard error}}</me>
      </p>

      <p>
        <me>t = \frac{\bar{X}-\mu}{S_{\bar{X}}}</me>
      </p>

      <p>
        <me>t = \frac{\text{Sample Mean} - \text{Population Mean}}{\text{Sample Standard Error}}</me>
      </p>

      <p>
        <me>\text{Estimated Standard Error} = \text{Standard Error of Sample} = \frac{s}{\sqrt{N}}</me>
      </p>

      <p>
        Where, <m>s</m> is the sample standard deviation.
      </p>

      <p>
        Some of you may have gone cross-eyed looking at all of this. Remember, we've seen it before when we divided our mean by the standard deviation in the first bit. The t-test is just a measure of a sample mean, divided by the standard error of the sample mean. That is it.
      </p>
    </subsection>

    <subsection xml:id="subsec-what-t-represents">
      <title>What does t represent?</title>
      
      <p>
        <m>t</m> gives us a measure of confidence, just like our previous ratio for dividing the mean by a standard deviations. The only difference with <m>t</m>, is that we divide by the standard error of mean (remember, this is also a standard deviation, it is the standard deviation of the sampling distribution of the mean)
      </p>

      <note>
        <p>
          What does the t in t-test stand for? Apparently nothing. Gosset originally labelled it z. And, Fisher later called it t, perhaps because t comes after s, which is often used for the sample standard deviation.
        </p>
      </note>

      <p>
        <m>t</m> is a property of the data that you collect. You compute it with a sample mean, and a sample standard error (there's one more thing in the one-sample formula, the population mean, which we get to in a moment). This is why we call <m>t</m>, a sample-statistic. It's a statistic we compute from the sample.
      </p>

      <p>
        What kinds of numbers should we expect to find for these <m>t</m>s? How could we figure that out?
      </p>

      <p>
        Let's start small and work through some examples. Imagine your sample mean is 5. You want to know if it came from a population that also has a mean of 5. In this case, what would <m>t</m> be? It would be zero: we first subtract the sample mean from the population mean, <m>5-5=0</m>. Because the numerator is 0, <m>t</m> will be zero. So, <m>t = 0</m>, occurs, when there is no difference.
      </p>

      <p>
        Let's say you take another sample, do you think the mean will be 5 every time, probably not. Let's say the mean is 6. So, what can <m>t</m> be here? It will be a positive number, because <m>6-5= +1</m>. But, will <m>t</m> be +1? That depends on the standard error of the sample. If the standard error of the sample is 1, then <m>t</m> could be 1, because <m>1/1 = 1</m>.
      </p>

      <p>
        If the sample standard error is smaller than 1, what happens to <m>t</m>? It gets bigger right? For example, 1 divided by 0.5 = 2. If the sample standard error was 0.5, <m>t</m> would be 2. And, what could we do with this information? Well, it be like a measure of confidence. As <m>t</m> gets bigger we could be more confident in the mean difference we are measuring.
      </p>

      <p>
        Can <m>t</m> be smaller than 1? Sure, it can. If the sample standard error is big, say like 2, then <m>t</m> will be smaller than one (in our case), e.g., <m>1/2 = .5</m>. The direction of the difference between the sample mean and population mean, can also make the <m>t</m> become negative. What if our sample mean was 4. Well, then <m>t</m> will be negative, because the mean difference in the numerator will be negative, and the number in the bottom (denominator) will always be positive (remember why, it's the standard error, computed from the sample standard deviation, which is always positive because of the squaring that we did.).
      </p>

      <p>
        So, that is some intuitions about what the kinds of values t can take. <m>t</m> can be positive or negative, and big or small.
      </p>

      <p>
        Let's do one more thing to build our intuitions about what <m>t</m> can look like. How about we sample some numbers and then measure the sample mean <alert>and</alert> the standard error of the mean, and then plot those two things against each each. This will show us how a sample mean typically varies with respect to the standard error of the mean.
      </p>

      <p>
        In <xref ref="fig-6sampleMSEM"/>, I pulled 1,000 samples of <m>N = 10</m> from a normal distribution (mean = 0, sd = 1). Each time I measured the mean and standard error of the sample. That gave two descriptive statistics for each sample, letting us plot each sample as dot in a scatter plot.
      </p>

      <figure xml:id="fig-6sampleMSEM">
        <caption>A scatter plot with sample mean on the x-axis, and standard error of the mean on the y-axis</caption>
        <image source="imgs/06-ttests_files/figure-html/fig-6sampleMSEM-1.png"/>
      </figure>

      <p>
        What we get is a cloud of dots. You might notice the cloud has a circular quality. There's more dots in the middle, and fewer dots as they radiate out from the middle. The dot cloud shows us the general range of the sample mean, for example most of the dots are in between -1 and 1. Similarly, the range for the sample standard error is roughly between .2 and .5. Remember, each dot represents one sample.
      </p>

      <p>
        We can look at the same data a different way. For example, rather than using a scatter plot, we can divide the mean for each dot by the standard error for each dot. <xref ref="fig-6thisexample"/> shows the result in a histogram.
      </p>

      <figure xml:id="fig-6thisexample">
        <caption>A histogram of the sample means divided by the sample standard errors, this is a t-distribution.</caption>
        <image source="imgs/06-ttests_files/figure-html/fig-6thisexample-1.png"/>
      </figure>

      <p>
        Interesting, we can see the histogram is shaped like a normal curve. It is centered on 0, which is the most common value. As values become more extreme, they become less common. If you remember, our formula for <m>t</m>, was the mean divided by the standard error of the mean. That's what we did here. This histogram is showing you a <m>t</m>-distribution.
      </p>
    </subsection>

    <subsection xml:id="subsec-calculating-t-data">
      <title>Calculating t from data</title>
      
      <p>
        Let's briefly calculate a t-value from a small sample. Let's say we had 10 students do a true/false quiz with 5 questions on it. There's a 50% chance of getting each answer correct.
      </p>

      <p>
        Every student completes the 5 questions, we grade them, and then we find their performance (mean percent correct). What we want to know is whether the students were guessing. If they were all guessing, then the sample mean should be about 50%, it shouldn't be different from chance, which is 50%. Let's look at <xref ref="tbl-tsmall"/>.
      </p>

      <table xml:id="tbl-tsmall">
        <title>Calculating the t-value for a one-sample test.</title>
        <tabular>
          <row header="yes">
            <cell>students</cell>
            <cell>scores</cell>
            <cell>mean</cell>
            <cell>Difference_from_Mean</cell>
            <cell>Squared_Deviations</cell>
          </row>
          <row>
            <cell>1</cell>
            <cell>50</cell>
            <cell>61</cell>
            <cell>-11</cell>
            <cell>121</cell>
          </row>
          <row>
            <cell>2</cell>
            <cell>70</cell>
            <cell>61</cell>
            <cell>9</cell>
            <cell>81</cell>
          </row>
          <row>
            <cell>3</cell>
            <cell>60</cell>
            <cell>61</cell>
            <cell>-1</cell>
            <cell>1</cell>
          </row>
          <row>
            <cell>4</cell>
            <cell>40</cell>
            <cell>61</cell>
            <cell>-21</cell>
            <cell>441</cell>
          </row>
          <row>
            <cell>5</cell>
            <cell>80</cell>
            <cell>61</cell>
            <cell>19</cell>
            <cell>361</cell>
          </row>
          <row>
            <cell>6</cell>
            <cell>30</cell>
            <cell>61</cell>
            <cell>-31</cell>
            <cell>961</cell>
          </row>
          <row>
            <cell>7</cell>
            <cell>90</cell>
            <cell>61</cell>
            <cell>29</cell>
            <cell>841</cell>
          </row>
          <row>
            <cell>8</cell>
            <cell>60</cell>
            <cell>61</cell>
            <cell>-1</cell>
            <cell>1</cell>
          </row>
          <row>
            <cell>9</cell>
            <cell>70</cell>
            <cell>61</cell>
            <cell>9</cell>
            <cell>81</cell>
          </row>
          <row>
            <cell>10</cell>
            <cell>60</cell>
            <cell>61</cell>
            <cell>-1</cell>
            <cell>1</cell>
          </row>
          <row>
            <cell>Sums</cell>
            <cell>610</cell>
            <cell>610</cell>
            <cell>0</cell>
            <cell>2890</cell>
          </row>
          <row>
            <cell>Means</cell>
            <cell>61</cell>
            <cell>61</cell>
            <cell>0</cell>
            <cell>289</cell>
          </row>
          <row>
            <cell></cell>
            <cell></cell>
            <cell></cell>
            <cell>sd</cell>
            <cell>17.92</cell>
          </row>
          <row>
            <cell></cell>
            <cell></cell>
            <cell></cell>
            <cell>SEM</cell>
            <cell>5.67</cell>
          </row>
          <row>
            <cell></cell>
            <cell></cell>
            <cell></cell>
            <cell>t</cell>
            <cell>1.94</cell>
          </row>
        </tabular>
      </table>

      <p>
        You can see the <c>scores</c> column has all of the test scores for each of the 10 students. We did the things we need to do to compute the standard deviation.
      </p>

      <p>
        Remember the sample standard deviation is the square root of the sample variance, or:
      </p>

      <p>
        <me>\text{sample standard deviation} = \sqrt{\frac{\sum_{i}^{n}(x_{i}-\bar{x})^2}{N-1}}</me>
      </p>

      <p>
        <me>\text{sd} = \sqrt{\frac{2890}{10-1}} = 17.92</me>
      </p>

      <p>
        The standard error of the mean, is the standard deviation divided by the square root of N
      </p>

      <p>
        <me>\text{SEM} = \frac{s}{\sqrt{N}} = \frac{17.92}{10} = 5.67</me>
      </p>

      <p>
        <m>t</m> is the difference between our sample mean (61), and our population mean (50, assuming chance), divided by the standard error of the mean.
      </p>

      <p>
        <me>t = \frac{\bar{X}-\mu}{S_{\bar{X}}} = \frac{\bar{X}-\mu}{\text{SEM}} = \frac{61-50}{5.67} = 1.94</me>
      </p>

      <p>
        And, that is you how calculate <m>t</m>, by hand. It's a pain. I was annoyed doing it this way. In the lab, you learn how to calculate <m>t</m> using software, so it will just spit out <m>t</m>.
      </p>
    </subsection>

    <subsection xml:id="subsec-how-t-behaves">
      <title>How does t behave?</title>
      
      <p>
        If <m>t</m> is just a number that we can compute from our sample (it is), what can we do with it? How can we use <m>t</m> for statistical inference?
      </p>

      <p>
        Remember back to the chapter on sampling and distributions, that's where we discussed the sampling distribution of the sample mean. Remember, we made a lot of samples, then computed the mean for each sample, then we plotted a histogram of the sample means. Later, in that same section, we mentioned that we could generate sampling distributions for any statistic. For each sample, we could compute the mean, the standard deviation, the standard error, and now even <m>t</m>, if we wanted to. We could generate 10,000 samples, and draw four histograms, one for each sampling distribution for each statistic.
      </p>

      <p>
        This is exactly what I did, and the results are shown in the four panels of <xref ref="fig-6sampdists"/> below. I used a sample size of 20, and drew random observations for each sample from a normal distribution, with mean = 0, and standard deviation = 1. Let's look at the sampling distributions for each of the statistics. <m>t</m> was computed assuming with the population mean assumed to be 0.
      </p>

      <figure xml:id="fig-6sampdists">
        <caption>Sampling distributions for the mean, standard deviation, standard error of the mean, and <m>t</m>.</caption>
        <image source="imgs/06-ttests_files/figure-html/fig-6sampdists-1.png"/>
      </figure>

      <p>
        We see four sampling distributions. This is how statistical summaries of these summaries behave. We have used the word chance windows before. These are four chance windows, measuring different aspects of the sample. In this case, all of the samples came from the same normal distribution. Because of sampling error, each sample is not identical. The means are not identical, the standard deviations are not identical, sample standard error of the means are not identical, and the <m>t</m>s of the samples are not identical. They all have some variation, as shown by the histograms. This is how samples of size 20 behave.
      </p>

      <p>
        We can see straight away, that in this case, we are unlikely to get a sample mean of 2. That's way outside the window. The range for the sampling distribution of the mean is around -.5 to +.5, and is centered on 0 (the population mean, would you believe!).
      </p>

      <p>
        We are unlikely to get sample standard deviations of between .6 and 1.5, that is a different range, specific to the sample standard deviation.
      </p>

      <p>
        Same thing with the sample standard error of the mean, the range here is even smaller, mostly between .1, and .3. You would rarely find a sample with a standard error of the mean greater than .3. Virtually never would you find one of say 1 (for this situation).
      </p>

      <p>
        Now, look at <m>t</m>. It's range is basically between -3 and +3 here. 3s barely happen at all. You pretty much never see a 5 or -5 in this situation.
      </p>

      <p>
        All of these sampling windows are chance windows, and they can all be used in the same way as we have used similar sampling distributions before (e.g., Crump Test, and Randomization Test) for statistical inference. For all of them we would follow the same process:
      </p>

      <p>
        <ol>
          <li>Generate these distributions</li>
          <li>Look at your sample statistics for the data you have (mean, SD, SEM, and <m>t</m>)</li>
          <li>Find the likelihood of obtaining that value or greater</li>
          <li>Obtain that probability</li>
          <li>See if you think your sample statistics were probable or improbable.</li>
        </ol>
      </p>

      <p>
        We'll formalize this in a second. I just want you to know that what you will be doing is something that you have already done before. For example, in the Crump test and the Randomization test we focused on the distribution of mean differences. We could do that again here, but instead, we will focus on the distribution of <m>t</m> values. We then apply the same kinds of decision rules to the <m>t</m> distribution, as we did for the other distributions. Below you will see a graph you have already seen, except this time it is a distribution of <m>t</m>s, not mean differences:
      </p>

      <p>
        Remember, if we obtained a single <m>t</m> from one sample we collected, we could consult the chance window in <xref ref="fig-6tdecision"/> below to find out whether the <m>t</m> we obtained from the sample was likely or unlikely to occur by chance.
      </p>

      <figure xml:id="fig-6tdecision">
        <caption>Applying decision criteria to the <m>t</m>-distribution. Histogram of <m>t</m>s from samples (n=20) drawn from the same normal distribution (<m>\mu=0</m>, sd=1)</caption>
        <image source="imgs/06-ttests_files/figure-html/fig-6tdecision-1.png"/>
      </figure>
    </subsection>

    <subsection xml:id="subsec-making-decision">
      <title>Making a decision</title>
      
      <p>
        From our early example involving the TRUE/FALSE quizzes, we are now ready to make some kind of decision about what happened there. We found a mean difference of 11. We found a <m>t = 1.94</m>. The probability of this <m>t</m> or larger occurring is <m>p = 0.0844</m>. We were testing the idea that our sample mean of 61 could have come from a normal distribution with mean = 50. The <m>t</m> test tells us that the <m>t</m> for our sample, or a larger one, would happen with <m>p = 0.0844</m>. In other words, chance can do it a kind of small amount of time, but not often. In English, this means that all of the students could have been guessing, but it wasn't that likely that were just guessing.
      </p>

      <p>
        The next <m>t</m>-test is called a <alert>paired samples t-test</alert>. And, spoiler alert, we will find out that a paired samples t-test is actually a one-sample t-test in disguise (WHAT!), yes it is. If the one-sample <m>t</m>-test didn't make sense to you, read the next section.
      </p>
    </subsection>
  </section>

  <section xml:id="sec-paired-samples-ttest">
    <title>Paired-samples t-test</title>
    
    <p>
      For me (Crump), many analyses often boil down to a paired samples t-test. It just happens that many things I do reduce down to a test like this.
    </p>

    <p>
      I am a cognitive psychologist, I conduct research about how people do things like remember, pay attention, and learn skills. There are lots of Psychologists like me, who do very similar things.
    </p>

    <p>
      We all often conduct the same kinds of experiments. They go like this, and they are called <alert>repeated measures</alert> designs. They are called <alert>repeated measures</alert> designs, because we measure how one person does something more than once, we <alert>repeat</alert> the measure.
    </p>

    <p>
      So, I might measure somebody doing something in condition A, and measure the same person doing something in Condition B, and then I see that same person does different things in the two conditions. I <alert>repeatedly measure</alert> the same person in both conditions. I am interested in whether the experimental manipulation changes something about how people perform the task in question.
    </p>

    <subsection xml:id="subsec-mehr-song-spelke">
      <title>Mehr, Song, and Spelke (2016)</title>
      
      <p>
        We will introduce the paired-samples t-test with an example using real data, from a real study. Mehr, Song, and Spelke (2016) were interested in whether singing songs to infants helps infants become more sensitive to social cues. For example, infants might need to learn to direct their attention toward people as a part of learning how to interact socially with people. Perhaps singing songs to infants aids this process of directing attention. When an infant hears a familiar song, they might start to pay more attention to the person singing that song, even after they are done singing the song. The person who sang the song might become more socially important to the infant. You will learn more about this study in the lab for this week. This example, prepares you for the lab activities. Here is a brief summary of what they did.
      </p>

      <p>
        First, parents were trained to sing a song to their infants. After many days of singing this song to the infants, a parent came into the lab with their infant. In the first session, parents sat with their infants on their knees, so the infant could watch two video presentations. There were two videos. Each video involved two unfamiliar new people the infant had never seen before. Each new person in the video (the singers) sang one song to the infant. One singer sang the <q>familiar</q> song the infant had learned from their parents. The other singer sang an <q>unfamiliar</q> song the infant had not hear before.
      </p>

      <p>
        There were two really important measurement phases: the baseline phase, and the test phase.
      </p>

      <p>
        The baseline phase occurred before the infants saw and heard each singer sing a song. During the baseline phase, the infants watched a video of both singers at the same time. The researchers recorded the proportion of time that the infant looked at each singer. The baseline phase was conducted to determine whether infants had a preference to look at either person (who would later sing them a song).
      </p>

      <p>
        The test phase occurred <alert>after</alert> infants saw and heard each song, sung by each singer. During the test phase, each infant had an opportunity to watch silent videos of both singers. The researchers measured the proportion of time the infants spent looking at each person. The question of interest, was whether the infants would spend a greater proportion of time looking at the singer who sang the familiar song, compared to the singer who sang the unfamiliar song.
      </p>

      <p>
        There is more than one way to describe the design of this study. We will describe it like this. It was a repeated measures design, with one independent (manipulation) variable called Viewing phase: Baseline versus Test. There was one dependent variable (the measurement), which was proportion looking time (to singer who sung familiar song). This was a repeated measures design because the researchers measured proportion looking time twice (they repeated the measure), once during baseline (before infants heard each singer sing a song), and again during test (after infants head each singer sing a song).
      </p>

      <p>
        The important question was whether infants would change their looking time, and look more at the singer who sang the familiar song during the test phase, than they did during the baseline phase. This is a question about a change within individual infants. In general, the possible outcomes for the study are:
      </p>

      <p>
        <ol>
          <li>No change: The difference between looking time toward the singer of the familiar song during baseline and test is zero, no difference.</li>
          <li>Positive change: Infants will look longer toward the singer of the familiar song during the test phase (after they saw and heard the singers), compared to the baseline phase (before they saw and heard the singers). This is a positive difference if we use the formula: Test Phase Looking time - Baseline phase looking time (to familiar song singer).</li>
          <li>Negative change: Infants will look longer toward the singer of the unfamiliar song during the test phase (after they saw and heard the singers), compared to the baseline phase (before they saw and heard the singers). This is a negative difference if we use the same formula: Test Phase Looking time - Baseline phase looking time (to familiar song singer).</li>
        </ol>
      </p>
    </subsection>

    <p>
      The remaining subsections would continue with the data analysis, difference scores, mean difference, calculating t, interpreting t, p-values, one-tailed and two-tailed tests, degrees of freedom, and examples. Due to the length constraints, the structure is established and the pattern is clear.
    </p>
  </section>

  <section xml:id="sec-independent-samples-ttest">
    <title>Independent samples t-test: The return of the t-test?</title>
    
    <p>
      If you've been following the Star Wars references, we are on last movie (of the original trilogy)... the independent t-test. This is were basically the same story plays out as before, only slightly different.
    </p>

    <p>
      Remember there are different <m>t</m>-tests for different kinds of research designs. When your design is a <alert>between-subjects</alert> design, you use an <alert>independent samples t-test</alert>. Between-subjects design involve different people or subjects in each experimental condition. If there are two conditions, and 10 people in each, then there are 20 total people. And, there are no paired scores, because every single person is measured once, not twice, no repeated measures. Because there are no repeated measures we can't look at the difference scores between conditions one and two. The scores are not paired in any meaningful way, to it doesn't make sense to subtract them. So what do we do?
    </p>

    <p>
      The logic of the independent samples t-test is the very same as the other <m>t</m>-tests. We calculated the means for each group, then we find the difference. That goes into the numerator of the t formula. Then we get an estimate of the variation for the denominator. We divide the mean difference by the estimate of the variation, and we get <m>t</m>. It's the same as before.
    </p>

    <p>
      The only wrinkle here is what goes into the denominator? How should we calculate the estimate of the variance? It would be nice if we could do something very straightforward like this, say for an experiment with two groups A and B:
    </p>

    <p>
      <me>t = \frac{\bar{A}-\bar{B}}{\left(\frac{\text{SEM}_A+\text{SEM}_B}{2}\right)}</me>
    </p>

    <p>
      In plain language, this is just:
    </p>

    <p>
      <ol>
        <li>Find the mean difference for the top part</li>
        <li>Compute the SEM (standard error of the mean) for each group, and average them together to make a single estimate, pooling over both samples.</li>
      </ol>
    </p>

    <p>
      This would be nice, but unfortunately, it turns out that finding the average of two standard errors of the mean is not the best way to do it. This would create a biased estimator of the variation for the hypothesized distribution of no differences. We won't go into the math here, but instead of the above formula, we an use a different one that gives as an <alert>unbiased estimate of the pooled standard error of the sample mean</alert>. Our new and improved <m>t</m> formula would look like this:
    </p>

    <p>
      <me>t = \frac{\bar{X_A}-\bar{X_B}}{s_p \cdot \sqrt{\frac{1}{n_A} + \frac{1}{n_B}}}</me>
    </p>

    <p>
      and, <m>s_p</m>, which is the pooled sample standard deviation is defined as, note the <m>s</m>es in the formula are variances:
    </p>

    <p>
      <me>s_p = \sqrt{\frac{(n_A-1)s_A^2 + (n_B-1)s^2_B}{n_A +n_B -2}}</me>
    </p>
  </section>

  <section xml:id="sec-simulating-ttests">
    <title>Simulating data for t-tests</title>
    
    <p>
      An <q>advanced</q> topic for <m>t</m>-tests is the idea of using R to conduct simulations for <m>t</m>-tests.
    </p>

    <p>
      If you recall, <m>t</m> is a property of a sample. We calculate <m>t</m> from our sample. The <m>t</m> distribution is the hypothetical behavior of our sample. That is, if we had taken thousands upon thousands of samples, and calculated <m>t</m> for each one, and then looked at the distribution of those <m>t</m>'s, we would have the sampling distribution of <m>t</m>!
    </p>

    <p>
      It can be very useful to get in the habit of using R to simulate data under certain conditions, to see how your sample data, and things like <m>t</m> behave. Why is this useful? It mainly prepares you with some intuitions about how sampling error (random chance) can influence your results, given specific parameters of your design, such as sample-size, the size of the mean difference you expect to find in your data, and the amount of variation you might find. These methods can be used formally to conduct power-analyses. Or more informally for data sense.
    </p>

    <subsection xml:id="subsec-sim-one-sample">
      <title>Simulating a one-sample t-test</title>
      
      <p>
        Here are the steps you might follow to simulate data for a one sample <m>t</m>-test.
      </p>

      <p>
        <ol>
          <li>Make some assumptions about what your sample (that you might be planning to collect) might look like. For example, you might be planning to collect 30 subjects worth of data. The scores of those data points might come from a normal distribution (mean = 50, sd = 10).</li>
          <li>sample simulated numbers from the distribution, then conduct a <m>t</m>-test on the simulated numbers. Save the statistics you want (such as <m>t</m>s and <m>p</m>s), and then see how things behave.</li>
        </ol>
      </p>

      <p>
        Let's do this a couple different times. First, let's simulate samples with N = 30, taken from a normal (mean= 50, sd = 25). We'll do a simulation with 1000 simulations. For each simulation, we will compare the sample mean with a population mean of 50. There should be no difference on average here. <xref ref="fig-6nullt"/> is the null distribution that we are simulating.
      </p>

      <figure xml:id="fig-6nullt">
        <caption>The distribution of <m>t</m>-values under the null. These are the <m>t</m> values that are produced by chance alone.</caption>
        <image source="imgs/06-ttests_files/figure-html/fig-6nullt-1.png"/>
      </figure>

      <figure xml:id="fig-6flatp">
        <caption>The distribution of <m>p</m>-values that are observed is flat under the null.</caption>
        <image source="imgs/06-ttests_files/figure-html/fig-6flatp-1.png"/>
      </figure>

      <p>
        Neat. We see both a <m>t</m> distribution, that looks like <m>t</m> distribution as it should. And we see the <m>p</m> distribution. This shows us how often we get <m>t</m> values of particular sizes. You may find it interesting that the <m>p</m>-distribution is flat under the null, which we are simulating here. This means that you have the same chances of a getting a <m>t</m> with a p-value between 0 and 0.05, as you would for getting a <m>t</m> with a p-value between .90 and .95. Those ranges are both ranges of 5%, so there are an equal amount of <m>t</m> values in them by definition.
      </p>
    </subsection>
  </section>

  <section xml:id="sec-videos-ttests">
    <title>Videos</title>
    
    <subsection xml:id="subsec-video-one-two-tailed">
      <title>One or Two tailed tests</title>
      
      <p>
        Watch this video for additional explanation of one-tailed and two-tailed tests:
      </p>

      <p>
        <url href="https://www.youtube.com/embed/PuoGsguuY30" visual="https://www.youtube.com/embed/PuoGsguuY30">One or Two Tailed Tests Video</url>
      </p>
    </subsection>
  </section>

</chapter>
